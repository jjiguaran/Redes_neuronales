{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Ejercicio 1 - Regresion Logística con Keras.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"KGzWert7cNuF","colab_type":"text"},"source":["Regresion Logística con Keras\n","\n","En este ejercicio, tu objetivo será entrenar modelos de Regresión Logística utilizando Keras (y Tensorflow como backend) para familiarizarte con la librería.\n","\n"]},{"cell_type":"code","metadata":{"id":"9PTXUGA7cNuG","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib \n","import matplotlib.pyplot as plt\n","import utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9-XeSzlkcNuQ","colab_type":"text"},"source":["# Entrena un modelo de Regresión Logística con Keras para el dataset de estudio 2D\n","\n","El siguiente código carga un dataset de prueba con 2 dimensiones de entrada y una de salida.\n","\n","Luego crea un modelo de regresión logística con Keras, y visualiza sus pesos iniciales. \n","\n","Es importante notar tres cosas:\n","\n","1. La métrica utilizada es `'sparse_categorical_crossentropy'`, es decir la entropía cruzada. Esta es la misma métrica vista en la teoría de Regresión Logística Múltiple.\n","\n","2. El optimizador es una clase que define el algoritmo para minimizar el error cuadrático. En general, son todas variantes de descenso de gradiente. En este caso, estamos utilizando descenso de gradiente estocástico (`keras.optimizers.SGD`), que es igual al descenso de gradiente pero realiza cada actualización de los parámetros con un subconjunto de los ejemplos del dataset. \n","\n","3. El método para entrenar el modelo es `fit`. En este caso, el parámetro `lr` lo recibe el optimizador, pero `fit` recibe la cantidad de iteraciones (`epochs`) y el tamaño del batch para el SGD (`batch_size`).\n","\n","\n","Al finalizar el entrenamiento, observá los valores del vector de pesos `w`. ¿A qué atributo o variable de entrada le da más importancia el modelo?\n"]},{"cell_type":"code","metadata":{"id":"U3UTcRC3cNuU","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import keras\n","import numpy as np\n","import utils \n","\n","# Carga del dataset\n","import os\n","dataset_path=os.path.join(\"datasets_clasificacion\",\"study_logistic_2d.csv\")\n","\n","\n","data=np.loadtxt(open(dataset_path, \"rb\"), delimiter=\",\", skiprows=1)\n","x,y=data[:,0:2],data[:,2]\n","# cantidad de ejemplos y dimension de entrada\n","n,d_in=x.shape\n","\n","\n","# calcula la cantidad de clases\n","classes=int(y.max()+1)\n","\n","print(\"Información del conjunto de datos:\")\n","print(f\"Ejemplos: {n}\")\n","print(f\"Variables de entrada: {d_in}\")\n","print(f\"Cantidad de clases: {classes}\")\n","\n","\n","\n","\n","# Creación del modelo logítico\n","print(\"Inicialización aleatoria del modelo (podes volver a correr esta celda para obtener otros resultados)\")\n","# Creo un modelo lineal\n","modelo = keras.Sequential([\n","    # la activación softmax hace que la salida sean probabilidades\n","    keras.layers.Dense(classes,input_shape=(d_in,), activation='softmax')])\n","\n","# visualización del modelo inicial\n","utils.plot_regresion_logistica2D(modelo,x,y,title=\"Modelo inicial\")\n","\n","\n","modelo.compile(\n","  optimizer=keras.optimizers.SGD(lr=0.001), \n","  loss='sparse_categorical_crossentropy', \n","  # metricas para ir calculando en cada iteracion \n","  # Agregamos el accuracy del modelo\n","  metrics=['accuracy'], \n",")\n","\n","# Entrenamiento del modelo\n","modelo.fit(x,y,epochs=1000,batch_size=16)\n","\n","# visualiza el modelo y los datos\n","w,b=modelo.get_weights()\n","print(f\"w: {w}, b: {b}\")\n","utils.plot_regresion_logistica2D(modelo,x,y,title=\"Modelo Final\")\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"awgeC0RucNub","colab_type":"text"},"source":["# Reentrenamiento con otro optimizador\n","\n","En la mayoría de los casos, el modelo no converge adecuadamente, aún cambiando la tasa de aprendizaje. Podemos utilizar el optimizador [Adam](https://arxiv.org/abs/1412.6980) que logra que el modelo converja aún cuando `SGD` no puede.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"O4ueodPAcNue","colab_type":"code","colab":{}},"source":["modelo = keras.Sequential([\n","    # la activación softmax hace que la salida sean probabilidades\n","    keras.layers.Dense(classes,input_shape=(d_in,), activation='softmax')])\n","\n","modelo.compile(\n","  optimizer='adam', # Cambiamos el optimizador a ADAM\n","  loss='sparse_categorical_crossentropy', \n","  metrics=['accuracy'], \n",")\n","\n","# Entrenamiento del modelo\n","modelo.fit(x,y,epochs=1000,batch_size=16)\n","\n","utils.plot_regresion_logistica2D(modelo,x,y,title=\"Modelo Final con Adam\")\n","w,b=modelo.get_weights()\n","print(f\"w: {w}, b: {b}\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dH8ikymBcNul","colab_type":"text"},"source":["# Entrenamiento con normalización de los datos\n","\n","Una mejor opción para lograr que el modelo converja es normalizar los datos de entrada. En este caso vemos como dicha normalización permite que el modelo siempre converja. \n","\n","\n","Implementa la normalización media/desviación estándar de los datos de la variable x_norm, que es una copia de x.\n","\n","\n","Al finalizar el entrenamiento, observá los valores del vector de pesos `w`. ¿A qué atributo o variable de entrada le da más importancia el modelo? ¿Cambió con la normalización?"]},{"cell_type":"code","metadata":{"id":"Q9LtkflscNul","colab_type":"code","colab":{}},"source":["x_norm=x.copy()\n","# Normalizacion mu/std de los datos de entrada\n","# TODO\n","for i in range(d_in):\n","    # normalizo la columna i restando su media y dividiendo por su desv. est.\n","    pass\n","# fin TODO\n","\n","\n","    \n","modelo = keras.Sequential([\n","    # la activación softmax hace que la salida sean probabilidades\n","    keras.layers.Dense(classes,input_shape=(d_in,), activation='softmax')])\n","\n","\n","\n","utils.plot_regresion_logistica2D(modelo,x_norm,y,title=\"Modelo Inicial\")\n","\n","modelo.compile(\n","  optimizer=keras.optimizers.SGD(lr=0.001), \n","  loss='sparse_categorical_crossentropy', \n","  metrics=['accuracy'], \n",")\n","\n","# Entrenamiento del modelo\n","modelo.fit(x_norm,y,epochs=1000,batch_size=16)\n","\n","# visualiza el modelo y los datos\n","\n","utils.plot_regresion_logistica2D(modelo,x_norm,y,title=\"Modelo Final\")\n","w,b=modelo.get_weights()\n","print(f\"w: {w}, b: {b}\")"],"execution_count":null,"outputs":[]}]}