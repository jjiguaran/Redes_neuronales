{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comando de Jupyter para que las imagenes se muestren automaticamente \n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Para las capas de las redes\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "from keras.datasets import mnist\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se normalizan las entradas\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Se agrega una dimension para hacer CNN (28, 28, 1)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "print(\"x_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension de entrada para la convolucion\n",
    "input_shape = (28, 28, 1)\n",
    "# calcula la cantidad de clases\n",
    "classes=int(Y_train.max()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capa Convolucional (Conv2D) - Capa Max Pooling (MaxPooling2D) - Capa de (Regresión Logística (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size = 7, activation='relu', input_shape=(input_shape), strides = 1))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.1226 - acc: 0.9631 - val_loss: 0.0564 - val_acc: 0.9817\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 25s 408us/step - loss: 0.0538 - acc: 0.9831 - val_loss: 0.0476 - val_acc: 0.9845\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 0.0400 - acc: 0.9875 - val_loss: 0.0395 - val_acc: 0.9880\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.0313 - acc: 0.9901 - val_loss: 0.0735 - val_acc: 0.9786\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.0264 - acc: 0.9914 - val_loss: 0.0423 - val_acc: 0.9872\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 25s 410us/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0489 - val_acc: 0.9881\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.0172 - acc: 0.9941 - val_loss: 0.0521 - val_acc: 0.9863\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 25s 419us/step - loss: 0.0138 - acc: 0.9956 - val_loss: 0.0571 - val_acc: 0.9840\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 0.0137 - acc: 0.9951 - val_loss: 0.0530 - val_acc: 0.9879\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_acc', mode='min', patience=5, verbose=1)\n",
    "\n",
    "model.compile(\n",
    "  optimizer=keras.optimizers.Adam(lr=0.001,beta_1=0.9,beta_2=0.999,amsgrad=False), \n",
    "  loss='sparse_categorical_crossentropy', \n",
    "  # metricas para ir calculando en cada iteracion o batch \n",
    "  # Agregamos el accuracy del modelo\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#Se incluye el early stopping en el fit\n",
    "history = model.fit(X_train, Y_train, epochs=10, callbacks=[es], validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.05301154109782219\n",
      "Test accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\t3x3\t1\tSi\t2\tReLU\t 6\t0.9783\t0.9763 <br>\n",
    "16\t3x3\t1\tSi\t2\tReLU\t 6\t0.9895\t0.9813 <br>\n",
    "64\t3x3\t1\tSi\t2\tReLU\t 6\t0.9935\t0.9838 <br>\n",
    "128\t3x3\t1\tSi\t2\tReLU\t 6\t0.9942\t0.9823 <br>\n",
    "4\t7x7\t1\tSi\t2\tReLU\t 6\t0.9824\t0.9826 <br>\n",
    "16\t7x7\t1\tSi\t2\tReLU\t 6\t0.9911\t0.9879 <br>\n",
    "64\t7x7\t1\tSi\t2\tReLU\t 9\t0.9951\t0.9879 <br>\n",
    "128\t7x7\t1\tSi\t2\tReLU\t 6\t0.9940\t0.9855 <br>\n",
    "64\t3x3\t2\tNo\t-\tReLU\t 7\t0.9683\t0.9667 <br>\n",
    "64\t3x3\t3\tNo\t-\tReLU\t 6\t0.9582\t0.9632 <br>\n",
    "64\t3x3\t1\tSi\t2\tTanH\t 6\t0.9870\t0.9765 <br>\n",
    "64\t3x3\t1\tSi\t2\tSigmoide\t 6\t0.9661\t0.9687 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para hacer todos los entrenamientos y exportar archivo csv con resultados\n",
    "kernel_size = [3,7]\n",
    "filtro = [4,16,64,128]\n",
    "stride_2d = [1,2,3]\n",
    "stride_mp =[0,2]\n",
    "funcion_act = ['softmax','tanh','relu']\n",
    "max_pooling = [0,1]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
